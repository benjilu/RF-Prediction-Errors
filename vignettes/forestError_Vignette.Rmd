---
title: "Forest Error Vignette"
author: "Beni Lu and Johanna Hardin"
date: "Sepemper 2019"
output: 
  pdf_document: 
    keep_tex: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
RNGkind(sample.kind="Rounding")
```

<a id="top"></a>


> [Introduction](#intro)

> [Installation](#install)

> [Instructions](#instructions)

> [Prediction Intervals](#pi)

> [Comparison with Other Packages](#comp)


<a id="intro"></a>

## Introduction

The `forestError` package estimates conditional mean squared prediction errors, conditional prediction intervals, and conditional error distributions for random forest predictions using methods introduced in Lu and Hardin (2019+) (in preparation). Because these estimates are conditional on the test observations' predictor values, each estimate is individualized. In other words, each squared error, interval, and error distribution estimate is specific to each test observation, accounting for possible response heterogeneity, random forest prediction bias, and/or random forest prediction variability across the predictor space. Simulation results suggest that the prediction intervals obtained from this method are narrower than those obtained from quantile regression forests and conformal inference and several orders of magnitude faster to compute than prediction intervals obtained via conformal inference.

In its current state, the main function in this package accepts regression random forests built using any of the following packages:

- `randomForest`,
- `randomForestSRC`,
- `ranger`, and
- `quantregForest`.

<a id="install"></a>

## Installation

Running the following lines of code in `R` will install this package from GitHub:

```
library(devtools)
devtools::install_github(repo = "benjilu/forestError")
``` 
<a id="instructions"></a>


## Instructions
See `documentation.pdf` for information on how to use this package. A portion of the example given in the documentation is reproduced below for convenience.


For demonstration purposes, we use the `airquality` dataset which is available in base R.  We use only the rows with no missing values.
```{r}
# load data
data(airquality)

# remove observations with missing predictor variable values
airquality <- airquality[complete.cases(airquality), ]
```


In order to show how the function works on training and test data, we split the ariquality into two such sets. 
```{r}
set.seed(4747)
# get number of observations and the response column index
n <- nrow(airquality)
response.col <- 1

# split data into training and test sets
train.ind <- sample(1:n, n * 0.8, replace = FALSE)
Xtrain <- airquality[train.ind, -response.col]
Ytrain <- airquality[train.ind, response.col]
Xtest <- airquality[-train.ind, -response.col]
Ytest <- airquality[-train.ind, response.col]
```


As mentioned above, the quantile forest error function accepts output from any of the standard Random Forest algorithms.   Below, we apply the error function to the `randomForest` function in the `randomForest` package.

When training the random forest using `randomForest`, `ranger`, or `quantregForest`, `keep.inbag` must be set to TRUE. When training the random forest using `randomForestSRC`, `membership` must be set to TRUE.

```{r}
library(randomForest)
library(forestError)

# fit random forest to the training data
rf <- randomForest::randomForest(Xtrain, Ytrain, nodesize = 5,
                   ntree = 500, keep.inbag = TRUE)

# get conditional mean squared prediction errors, conditional prediction
# intervals, and conditional empirical error distribution functions for
# the test observations
test.errors <- forestError::quantForestError(rf, Xtrain, Xtest, alpha = 0.05)
head(test.errors)
```

<a id="pi"></a>


## Prediction Intervals

Generally, we won't know the test response, but in this vignette (also typically available in simulation studies) the test response is given by `Ytest`.  We can use the test response to gauge how well the prediction errors captured the variability.

```{r}
library(tidyverse)

test.errors <- test.errors %>%
  cbind(Ytest) 
```


The plot below shows the relationship between the observed and predicted responses (in this case, Ozone measured in ppb), given by the black dots.  the prediction intervals are created using the random forest error output.  A few important aspects of the plot include the following:

* The prediction intervals seem to be larger for larger values of the respose, indicating that the interval widths are not homogenous.
* The error quantiles (purple lines) are clearly not symmetric for some of the predictions, as expected.
* Plus or minus one SE doesn't always contain the true response, but we wouldn't expect it to.
* Plus or minus two SEs seems (unnecessarily) wider than the error quantiles.

```{r}
test.errors %>% dplyr::arrange(Ytest) %>%
  ggplot() +
  geom_point(aes(x = Ytest, y = pred)) + 
  geom_linerange(aes(x = Ytest-1, 
                     ymin = pred + sqrt(error), 
                     ymax = pred - sqrt(error), 
                     color = "blue"), size=.3) + 
  geom_linerange(aes(x = Ytest, 
                     ymin = pred + 2*sqrt(error), 
                     ymax = pred - 2*sqrt(error), 
                     color = "orange"), size=.3) + 
  geom_linerange(aes(x = Ytest+1, 
                     ymin = lower, 
                     ymax = upper, 
                     color = "purple"), size=.3) +
  geom_abline(a=0,b=1) +
  ylab("Predicted Response") +
  xlab("Observed Response") +
  scale_color_identity(name = "Interval Type",
                       breaks = c("blue", "orange", "purple"),
                       labels = c("SE1", "SE2", "QuantErr"),
                       guide = "legend")
```

<a id="comp"></a>

## Comparison with Other Packages

Meinhausen (2006) wrote an R package to find quantile prediction intervals based on the quantiles of the response variables (as opposed to quantiles of the prediction erros, as our package does).  Prediction intervals can be compute with `quantredForest` and compared to intervals from our functions in `forestError`.

```{r}
library(quantregForest)
qrf <- quantregForest(x=Xtrain, y=Ytrain)
conditionalQuantiles  <- predict(qrf, Xtest, what=c(.025, .975))
conditionalMean <- predict(qrf,  Xtest, what=mean)

qrfPred <- data.frame(qrfMean = conditionalMean, 
                      qrfLower = conditionalQuantiles[,1],
                      qrfUpper = conditionalQuantiles[,2])

allPreds <- cbind(test.errors, qrfPred)
```


With all the predictions, we can compare our errors with the quantile predicitons of Meinshausen.  Note that by using the error quantiles (our method, purple), the resulting intevals are much narrower than using the response quantiels (Meinshausen (2006), green).

```{r}
allPreds %>% dplyr::arrange(Ytest) %>%
  ggplot() +
  geom_point(aes(x = Ytest, y = pred)) + 
  geom_point(aes(x = Ytest, y = qrfMean), color = "red") +
  geom_linerange(aes(x = Ytest-1, 
                     ymin = qrfLower, 
                     ymax = qrfUpper, 
                     color = "green"), size=.3) + 
  geom_linerange(aes(x = Ytest+1, 
                     ymin = lower, 
                     ymax = upper, 
                     color = "purple"), size=.3) +
  geom_abline(a=0,b=1) +
  ylab("Predicted Response") +
  xlab("Observed Response") +
  scale_color_identity(name = "Interval Type",
                       breaks = c("green", "purple"),
                       labels = c("qrf", "QuantErr"),
                       guide = "legend")
```


## License
See `DESCRIPTION` for information.

## Authors
Benjamin Lu and Johanna Hardin

## References
* B. Lu and J. Hardin. Individualized prediction errors and intervals for random forests. In preparation, 2019+.
* J. Lei, M. G’Sell, A. Rinaldo, R.J. Tibshirani, and L. Wasserman. Distribution-free predictive inference for regression. Journal of the American Statistical Association, 113:1094-1111, 2018.
* N. Meinshausen. Quantile regression forests. Journal of Machine Learning Research, 7:983–999, 2006.




