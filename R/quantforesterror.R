#' Quantify random forest prediction error
#'
#' Estimates the conditional mean squared prediction errors and conditional
#' prediction intervals of random forest predictions.
#'
#' Three possible sets of outputs are possible from this function depending
#' on the user's arguments for \code{alpha} and \code{conservative}.
#'
#' The most minimal output is a list containing the random forest predictions of
#' the test observations and the estimated conditional mean squared prediction
#' errors associated with each. This can be obtained by setting \code{alpha}
#' to \code{NA}.
#'
#' The second possible output is a list that includes, in addition to the
#' random forest predictions and the estimated prediction errors, conditional
#' prediction intervals for each test observation with level specified by
#' \code{alpha}. This can be obtained by setting \code{alpha} to a numeric
#' value and setting \code{conservative} to \code{FALSE}.
#'
#' The most extensive set of outputs includes, in addition to the above, a
#' second set of prediction intervals generated by resolving ties in the
#' empirical error distribution conservatively. Conservatively estimated
#' prediction intervals may be desirable when the number of observations is
#' relatively small. This output can be obtained by setting \code{alpha} to a
#' numeric value and setting \code{conservative} to \code{TRUE}.
#'
#' @param forest The random forest object being used for prediction.
#' @param X.train A \code{matrix} or \code{data.frame} with the observations
#'   that were used to train \code{forest}; each row should be an observation,
#'   and each column should be a predictor variable.
#' @param X.test A \code{matrix} or \code{data.frame} with the observations to
#'   be predicted; each row should be an observation, and each column should be
#'   a predictor variable.
#' @param alpha The type-I error rate desired for the conditional prediction
#'   intervals; set to \code{NA} if no prediction intervals are desired.
#'   Defauls to \code{0.05}.
#' @param conservative A \code{logical} indicating whether a second set of
#'   conditional prediction intervals should be estimated in which ties in the
#'   empirical error distribution should be resolved conservatively or not.
#'   Defaults to \code{TRUE}.
#' @param rcpp A \code{logical} indicating whether the weights should be
#'   computed using \code{Rcpp}. Recommended if the number of training
#'   observations, test observations, or trees is large. Defauls to \code{FALSE}.
#'
#' @return A list with the following possible elements, each in the form of a
#'   vector, as described in the details section:
#'
#'   \item{pred}{The random forest predictions of the test observations}
#'   \item{error}{The estimated conditional mean square prediction errors of
#'   the random forest predictions}
#'   \item{lower}{The estimated lower bounds of the conditional prediction
#'   intervals for the test observations}
#'   \item{upper}{The estimated upper bounds of the conditional prediction
#'   intervals for the test observations}
#'   \item{lowerCons}{The conservatively estimated lower bounds of the
#'   conditional prediction intervals for the test observations}
#'   \item{upperCons}{The conservatively estimated upper bounds of the
#'   conditional prediction intervals for the test observations}
#'
#' @author Benjamin Lu \code{<b.lu@berkeley.edu>}; Johanna Hardin \code{<jo.hardin@pomona.edu>}
#'
#' @examples
#' # load data
#' data(airquality)
#'
#' # remove observations with missing predictor variable values
#' airquality <- airquality[complete.cases(airquality), ]
#'
#' # get number of observations and the response column index
#' n <- nrow(airquality)
#' response.col <- 1
#'
#' # split data into training and test sets
#' train.ind <- sample(1:n, n * 0.9, replace = FALSE)
#' Xtrain <- airquality[train.ind, -response.col]
#' Ytrain <- airquality[train.ind, response.col]
#' Xtest <- airquality[-train.ind, -response.col]
#' Ytest <- airquality[-train.ind, response.col]
#'
#' # fit random forest to the training data
#' rf <- randomForest::randomForest(Xtrain, Ytrain, nodesize = 10,
#'                                  ntree = 500, keep.inbag = TRUE)
#'
#' # get conditional mean squared prediction errors and prediction
#' # intervals for the test observations
#' test.preds <- quantForestError(rf, Xtrain, Xtest)
#'
#' # get the same as above but without the conservative prediction
#' # intervals
#' test.preds <- quantForestError(rf, Xtrain, Xtest, conservative = FALSE)
#'
#' # get just the mean squared prediction error estimates
#' test.preds <- quantForestError(rf, Xtrain, Xtest, alpha = NA)
#'
#' @export
quantForestError <- function(forest, X.train, X.test, alpha = 0.05, conservative = TRUE, rcpp = FALSE) {

  # check forest, X.train, and X.test arguments for issues
  checkForest(forest)
  checkXtrainXtest(X.train, X.test)

  # get terminal nodes of all observations
  train.terminal.nodes <- attr(predict(forest, X.train, nodes = TRUE), "nodes")
  test.terminal.nodes <- attr(predict(forest, X.test, nodes = TRUE), "nodes")

  # get number of times each training observation appears in each tree
  bag.count <- forest$inbag

  # get the OOB prediction error of each training observation
  oob.errors <- forest$y - forest$predicted

  # get number of training and test observations
  n.train <- nrow(X.train)
  n.test <- nrow(X.test)

  # get test observation predictions
  test.preds <- predict(forest, X.test)

  # get the terminal nodes of the training observations in the trees in which they are OOB
  # (for all other trees, set the terminal node to be 0)
  train.oob.terminal.nodes <- train.terminal.nodes * as.numeric(bag.count == 0)

  # if the user wishes to compute cohabitants in R
  if (rcpp == FALSE) {

    # initialize dataframe
    oob.weights <- data.frame(matrix(rep(NA, n.test * n.train), nrow = n.test))

    # for each test observation
    for (test.obs in 1:n.test) {

      # get for each training observation the number of times it is an OOB cohabitant of the test observation and record it in the dataframe
      oob.weights[test.obs, ] <- rowSums(sweep(train.oob.terminal.nodes, MARGIN = 2, test.terminal.nodes[test.obs, ], "=="))
    }

  # else, if the user wishes to compute cohabitants in C++
  } else {

    # load Rcpp
    library(Rcpp)

    # source the C++ function
    sourceCpp("./src/cohabitantCount.cpp")

    # run C++ function
    oob.weights <- countOOBCohabitants(train.oob.terminal.nodes, test.terminal.nodes, n.train, n.test)
  }

  # for each test observation, convert the number of times each training observation
  # is an OOB cohabitant to the proportion of times each training observation is an
  # OOB cohabitant
  oob.weights <- oob.weights / rowSums(oob.weights)

  # get the MSPE2 for each test observation
  mspe2s <- as.matrix(oob.weights) %*% (oob.errors ^ 2)

  # if the user requests prediction intervals with a certain alpha
  if (!is.na(alpha)) {

    # check the alpha argument and the conservative argument for issues
    checkAlpha(alpha)
    checkConservative(conservative)

    # sort the OOB errors of the training observations
    ordered.oob.errors <- sort(oob.errors, index.return = TRUE)

    # sort the OOB weight assigned to each OOB error according to the value of
    # the OOB error, in ascending order
    ordered.oob.weights <- oob.weights[, ordered.oob.errors$ix]

    # get the index of the training observation for which the cumulative sum of the OOB weights
    # initially exceeds 0.025
    lower.ind <- apply(ordered.oob.weights, 1, FUN = function(x) max(min(which(cumsum(x) >= alpha / 2)), 1))
    # get the index of the training observation for which the cumulative sum of the OOB weights
    # last remains below 0.975
    upper.ind <- apply(ordered.oob.weights, 1, FUN = function(x) max(which(cumsum(x) <= 1 - (alpha / 2))))

    # get the corresponding OOB errors and use them to construct prediction intervals
    # for the test observations
    lower.bounds <- test.preds + ordered.oob.errors$x[lower.ind]
    upper.bounds <- test.preds + ordered.oob.errors$x[upper.ind]

    # if the user requests conservative prediction intervals as well, compute them
    if (conservative) {

      # get the index of the training observation for which the cumulative sum of the OOB weights
      # initially exceeds 0.025 (CONSERVATIVE)
      con.lower.ind <- apply(ordered.oob.weights, 1, FUN = function(x) max(max(which(cumsum(x) <= alpha / 2)), 1))
      # get the index of the training observation for which the cumulative sum of the OOB weights
      # last remains below 0.975 (CONSERVATIVE)
      con.upper.ind <- apply(ordered.oob.weights, 1, FUN = function(x) min(which(cumsum(x) >= 1 - (alpha / 2))))

      # get the corresponding OOB errors and use them to construct prediction intervals
      # for the test observations
      con.lower.bounds <- test.preds + ordered.oob.errors$x[con.lower.ind]
      con.upper.bounds <- test.preds + ordered.oob.errors$x[con.upper.ind]

      # return the test predictions, prediction error, prediction intervals,
      # and conservative prediction intervals
      output <- list(pred = test.preds,
                     error = as.vector(mspe2s),
                     lower = lower.bounds,
                     upper = upper.bounds,
                     lowerCons = con.lower.bounds,
                     upperCons = con.upper.bounds)

    # else return the test predictions, prediction error, and prediction intervals
    } else {
      output <- list(pred = test.preds,
                     error = as.vector(mspe2s),
                     lower = lower.bounds,
                     upper = upper.bounds)
    }

  # else return the test predictions and prediction error
  } else {
    output <- list(pred = test.preds,
                   error = as.vector(mspe2s))
  }

  # return the test predictions, prediction error, and prediction intervals
  return(output)
}
